#!/usr/bin/env python3
"""
AIé©±åŠ¨çš„æ¯æ—¥æ–°é—»æ±‡æ€»å™¨
ä½¿ç”¨OpenAI + MCP Fetch + Pythonå·®å¼‚æ£€æµ‹çš„æ™ºèƒ½å†…å®¹èšåˆç³»ç»Ÿ
"""

import os
import sys
import json
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from ai_content_extractor import AIContentExtractor
from utils.content_differ import ContentDiffer
from utils.digest_generator import DigestGenerator


class SmartDailyAggregator:
    """æ™ºèƒ½æ¯æ—¥å†…å®¹èšåˆå™¨"""

    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = self._load_config()

        # åˆå§‹åŒ–ç»„ä»¶
        ai_config = self.config.get('ai_config', {})
        self.ai_extractor = AIContentExtractor(ai_config)
        self.content_differ = ContentDiffer()
        self.digest_generator = DigestGenerator()

        # åˆå§‹åŒ–HTTPä¼šè¯
        self.session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("https://", adapter)
        self.session.mount("http://", adapter)

        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)


    def _build_url(self, source_config: Dict[str, Any]) -> str:
        """
        æ ¹æ®é…ç½®åŠ¨æ€æ„å»ºURL

        æ”¯æŒçš„æ¨¡å¼å˜é‡ï¼š
        - {year}: å¹´ä»½ (å¦‚: 2025)
        - {month}: æœˆä»½ (å¦‚: 9)
        - {month:02d}: è¡¥é›¶çš„æœˆä»½ (å¦‚: 09)
        """
        base_url = source_config.get('base_url', '')
        url_pattern = source_config.get('url_pattern', '')

        if not url_pattern:
            # å¦‚æœæ²¡æœ‰æ¨¡å¼ï¼Œç›´æ¥è¿”å›base_urlï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
            return source_config.get('url', base_url)

        # è·å–å½“å‰æ—¥æœŸ
        now = datetime.now(timezone.utc)

        # æ„å»ºURL
        try:
            path = url_pattern.format(
                year=now.year,
                month=now.month
            )
            full_url = base_url + path
            print(f"åŠ¨æ€ç”ŸæˆURL: {full_url}")
            return full_url
        except Exception as e:
            print(f"URLæ„å»ºå¤±è´¥: {e}")
            # é™çº§åˆ°base_url
            return base_url

    def _fetch_content_with_requests(self, url: str) -> str:
        """
        ä½¿ç”¨requestsåº“è·å–ç½‘é¡µå†…å®¹
        """
        try:
            print(f"æ­£åœ¨è·å–ç½‘é¡µå†…å®¹: {url}")

            response = self.session.get(url, timeout=30)
            response.raise_for_status()

            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '').lower()
            if 'text/html' not in content_type:
                print(f"âš ï¸ ç½‘é¡µå†…å®¹ç±»å‹ä¸æ˜¯HTML: {content_type}")
                return ""

            # è·å–ç¼–ç 
            encoding = response.encoding or 'utf-8'
            html_content = response.content.decode(encoding, errors='ignore')

            print(f"âœ… æˆåŠŸè·å–ç½‘é¡µå†…å®¹ï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦")
            return html_content

        except requests.exceptions.RequestException as e:
            print(f"âŒ è·å–ç½‘é¡µå†…å®¹å¤±è´¥: {e}")
            return ""
        except Exception as e:
            print(f"âŒ å¤„ç†ç½‘é¡µå†…å®¹æ—¶å‡ºé”™: {e}")
            return ""


    def process_source(self, source_config: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ•°æ®æº"""
        source_name = source_config['name']

        print(f"\nğŸ” å¤„ç†æ•°æ®æº: {source_config['display_name']}")

        try:
            # 1. åŠ¨æ€æ„å»ºURL
            source_url = self._build_url(source_config)

            # 2. è·å–ç½‘é¡µå†…å®¹ (ä½¿ç”¨requests)
            html_content = self._fetch_content_with_requests(source_url)
            if not html_content:
                print(f"  âš ï¸ æ— æ³•è·å– {source_name} çš„ç½‘é¡µå†…å®¹")
                return {
                    'source': source_config,
                    'new_recommendations': [],
                    'status': 'fetch_failed'
                }

            # 3. AIæå–ä»Šæ—¥å†…å®¹
            print(f"  ğŸ¤– ä½¿ç”¨AIæå–å†…å®¹...")
            current_data = self.ai_extractor.extract_recommendations(
                html_content,
                source_config
            )

            # ç›´æ¥ä½¿ç”¨ä»Šæ—¥æå–çš„æ¨èå†…å®¹
            recommendations = current_data.get('recommendations', [])
            print(f"  âœ… å®Œæˆï¼Œæ‰¾åˆ° {len(recommendations)} ä¸ªä»Šæ—¥æ¨è")

            return {
                'source': source_config,
                'new_recommendations': recommendations,
                'total_extracted': len(recommendations),
                'status': 'success'
            }

        except Exception as e:
            print(f"  âŒ å¤„ç† {source_name} æ—¶å‡ºé”™: {e}")
            return {
                'source': source_config,
                'new_recommendations': [],
                'status': 'error',
                'error': str(e)
            }

    def run(self) -> bool:
        """è¿è¡Œæ™ºèƒ½èšåˆä»»åŠ¡"""
        print("ğŸš€ å¼€å§‹æ‰§è¡ŒAIé©±åŠ¨çš„æ¯æ—¥å†…å®¹èšåˆ...")
        print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        sources_data = {}
        total_new_items = 0

        # å¤„ç†æ¯ä¸ªå¯ç”¨çš„æ•°æ®æº
        enabled_sources = [
            source for source in self.config['sources']
            if source.get('enabled', True)
        ]

        print(f"ğŸ“‹ å°†å¤„ç† {len(enabled_sources)} ä¸ªæ•°æ®æº")

        for source_config in enabled_sources:
            result = self.process_source(source_config)

            source_name = source_config['name']
            sources_data[source_name] = {
                'config': source_config,
                'new_articles': result['new_recommendations']  # ä¿æŒä¸åŸæ¥å£å…¼å®¹
            }

            total_new_items += len(result['new_recommendations'])

        # ç”Ÿæˆæ¯æ—¥æ±‡æ€»
        if total_new_items > 0:
            print(f"\nğŸ“ ç”Ÿæˆæ¯æ—¥æ±‡æ€» (å…± {total_new_items} ä¸ªæ–°é¡¹ç›®)...")

            output_dir = os.path.join(
                os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                'data', 'daily-digest'
            )
            output_file = self.digest_generator.get_output_filename(output_dir)

            success = self.digest_generator.generate_daily_digest(sources_data, output_file)

            if success:
                print(f"âœ… æ¯æ—¥æ±‡æ€»ç”ŸæˆæˆåŠŸ: {os.path.basename(output_file)}")
                print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {output_file}")
                return True
            else:
                print("âŒ æ¯æ—¥æ±‡æ€»ç”Ÿæˆå¤±è´¥")
                return False
        else:
            print("\nğŸ“­ ä»Šæ—¥æ²¡æœ‰å‘ç°æ–°å¢å†…å®¹")
            return False

    def add_new_source(self, name: str, base_url: str, url_pattern: str, display_name: str, icon: str = "ğŸ”—") -> bool:
        """åŠ¨æ€æ·»åŠ æ–°æ•°æ®æº"""
        new_source = {
            "name": name,
            "display_name": display_name,
            "base_url": base_url,
            "url_pattern": url_pattern,
            "icon": icon,
            "enabled": True
        }

        self.config['sources'].append(new_source)

        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, ensure_ascii=False, indent=2)
            print(f"âœ… æ–°æ•°æ®æº '{display_name}' æ·»åŠ æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–°æ•°æ®æºå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– AIé©±åŠ¨çš„æ¯æ—¥æ–°é—»æ±‡æ€»å™¨")
    print("=" * 60)

    # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, '..', 'config', 'sources.json')

    # åˆ›å»ºå¹¶è¿è¡Œèšåˆå™¨
    try:
        aggregator = SmartDailyAggregator(config_path)
        success = aggregator.run()

        print("\n" + "=" * 60)
        if success:
            print("ğŸ‰ ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼")
        else:
            print("âš ï¸  ä»»åŠ¡å®Œæˆï¼Œä½†æ²¡æœ‰æ–°å†…å®¹")
        print("=" * 60)

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ä»»åŠ¡è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()