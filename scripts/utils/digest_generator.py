from typing import List, Dict
from datetime import datetime
import pytz
import os
import glob


class DigestGenerator:
    """æ—¥æŠ¥ç”Ÿæˆå™¨"""

    def __init__(self, timezone: str = "Asia/Shanghai", config: Dict = None):
        self.timezone = pytz.timezone(timezone)
        self.config = config or {}

    def generate_daily_digest(self, sources_data: Dict[str, Dict], output_path: str) -> bool:
        """ç”Ÿæˆæ¯æ—¥æ±‡æ€»æ–‡æ¡£"""
        try:
            # è·å–å½“å‰æ—¶é—´
            now = datetime.now(self.timezone)
            date_str = now.strftime('%Y-%m-%d')
            time_str = now.strftime('%Y-%m-%d %H:%M:%S')

            # ç»Ÿè®¡æ€»çš„æ–°å¢é¡¹ç›®æ•°
            total_new_items = sum(len(data['new_articles']) for data in sources_data.values())

            if total_new_items == 0:
                print("ä»Šæ—¥æ²¡æœ‰æ–°å¢å†…å®¹")
                return False

            # ç”ŸæˆMarkdownå†…å®¹
            markdown_content = self._generate_markdown(sources_data, date_str, time_str, total_new_items)

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)

            print(f"æ¯æ—¥æ±‡æ€»å·²ç”Ÿæˆ: {output_path}")
            print(f"åŒ…å« {len(sources_data)} ä¸ªæ•°æ®æºï¼Œ{total_new_items} ä¸ªæ–°å¢é¡¹ç›®")

            # æ¸…ç†æ—§æ–‡ä»¶
            self._cleanup_old_files(output_path)

            return True

        except Exception as e:
            print(f"ç”Ÿæˆæ¯æ—¥æ±‡æ€»å¤±è´¥: {e}")
            return False

    def _generate_markdown(self, sources_data: Dict, date_str: str, time_str: str, total_items: int) -> str:
        """ç”ŸæˆMarkdownå†…å®¹"""
        lines = [
            f"# æ¯æ—¥å‘ç°æ±‡æ€» - {date_str}",
            "",
            f"> æœ¬æ–‡æ¡£æ±‡æ€»äº†ä»Šæ—¥å„å¤§æ¨èç½‘ç«™çš„æ–°å¢å†…å®¹",
            ""
        ]

        # ä¸ºæ¯ä¸ªæ•°æ®æºæ·»åŠ å†…å®¹
        for source_name, data in sources_data.items():
            config = data['config']
            new_articles = data['new_articles']

            if not new_articles:
                continue

            lines.extend([
                f"## {config['icon']} {config['display_name']} ({source_name})",
                ""
            ])

            # æ·»åŠ æ¯ä¸ªæ–°å¢é¡¹ç›®
            for article in new_articles:
                if isinstance(article, dict):
                    # å¤„ç†å­—å…¸æ ¼å¼çš„æ¨èé¡¹ç›®
                    markdown_item = self._dict_to_markdown(article)
                    lines.append(markdown_item)
                else:
                    # å¤„ç†æœ‰to_markdownæ–¹æ³•çš„å¯¹è±¡
                    lines.append(article.to_markdown())

            lines.append("")

        # æ·»åŠ é¡µè„šä¿¡æ¯
        lines.extend([
            "---",
            "",
            f"**æ›´æ–°æ—¶é—´**: {time_str}  ",
            f"**æ•°æ®æº**: {len([s for s in sources_data.values() if s['new_articles']])} ä¸ªç½‘ç«™  ",
            f"**æ–°å¢é¡¹ç›®**: {total_items} ä¸ª  ",
            "",
            "<!-- Generated by Daily News Aggregator -->"
        ])

        return "\n".join(lines)

    def _dict_to_markdown(self, article: Dict) -> str:
        """å°†å­—å…¸æ ¼å¼çš„æ¨èé¡¹ç›®è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        title = article.get('title', 'æœªçŸ¥æ ‡é¢˜')
        url = article.get('url', '')
        description = article.get('description', '')

        # æ„å»ºmarkdownæ ¼å¼
        markdown_parts = []

        # æ ‡é¢˜å’Œé“¾æ¥
        if url:
            markdown_parts.append(f"**[{title}]({url})**")
        else:
            markdown_parts.append(f"**{title}**")

        # æè¿°
        if description:
            markdown_parts.append(f"  \n{description}")

        # å…¶ä»–ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦çš„è¯å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ï¼‰
        # æš‚æ—¶ä¸æ·»åŠ ä»»ä½•é¢å¤–ä¿¡æ¯ï¼Œä¿æŒç®€æ´

        return "\n".join(markdown_parts) + "\n"

    def _cleanup_old_files(self, current_file_path: str):
        """æ¸…ç†æ—§çš„Markdownæ–‡ä»¶ï¼Œä¿æŒæ–‡ä»¶æ•°é‡é™åˆ¶"""
        try:
            # ä»é…ç½®ä¸­è·å–æœ€å¤§æ–‡ä»¶æ•°ï¼Œé»˜è®¤30
            max_files = self.config.get('output_config', {}).get('max_files', 30)

            # è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•
            output_dir = os.path.dirname(current_file_path)

            # æŸ¥æ‰¾æ‰€æœ‰.mdæ–‡ä»¶
            md_files = glob.glob(os.path.join(output_dir, "*.md"))

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            md_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)

            # å¦‚æœæ–‡ä»¶æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤å¤šä½™çš„
            if len(md_files) > max_files:
                files_to_delete = md_files[max_files:]
                for file_path in files_to_delete:
                    try:
                        os.remove(file_path)
                        print(f"ğŸ—‘ï¸  åˆ é™¤æ—§æ–‡ä»¶: {os.path.basename(file_path)}")
                    except Exception as e:
                        print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

                print(f"ğŸ“ ä¿ç•™æœ€æ–°çš„ {max_files} ä¸ªæ–‡ä»¶ï¼Œåˆ é™¤äº† {len(files_to_delete)} ä¸ªæ—§æ–‡ä»¶")
            else:
                print(f"ğŸ“ å½“å‰æœ‰ {len(md_files)} ä¸ªæ–‡ä»¶ï¼Œæœªè¶…è¿‡é™åˆ¶ {max_files}")

        except Exception as e:
            print(f"æ¸…ç†æ—§æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def get_output_filename(self, base_dir: str) -> str:
        """è·å–è¾“å‡ºæ–‡ä»¶å"""
        now = datetime.now(self.timezone)
        date_str = now.strftime('%Y-%m-%d')
        return os.path.join(base_dir, f"daily-digest-{date_str}.md")